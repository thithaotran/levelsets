{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# plotting lib(s) and updated default plot settings\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib widget\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = 'L2_CIFAR10_CONV'\n",
    "RANGE_REG_PENALTY = sorted(np.logspace(-6, 6, num=13, endpoint=True).tolist() + [0.0])\n",
    "NUM_EXP = int(len([f for f in os.listdir(EXPERIMENT) if 'npz' in f])/len(RANGE_REG_PENALTY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Log Dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumps = [f for f in os.listdir(EXPERIMENT) if 'npz' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.load(os.path.join(EXPERIMENT, dumps[0])).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Metric Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_stats(metric, trans_fns = [np.mean, np.std]):\n",
    "    stats_arr = []\n",
    "    for idx, reg_pen in enumerate(RANGE_REG_PENALTY, start=1):\n",
    "        dumps_idx = [f for f in dumps if str(idx) in f]\n",
    "        temp = []\n",
    "        for dmp in dumps_idx:\n",
    "            arr = np.load(os.path.join(EXPERIMENT, dmp))\n",
    "            temp.append(arr[metric][-1])\n",
    "        stats_arr.append([idx, reg_pen]+[f(temp) for f in trans_fns])\n",
    "    return stats_arr\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric_stats('val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric_stats('val_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_endpoint(idx):\n",
    "\n",
    "    dumps_idx = [f for f in dumps if str(idx) in f]\n",
    "    temp = []\n",
    "    for dmp in dumps_idx:\n",
    "        arr = np.load(os.path.join(EXPERIMENT, dmp))\n",
    "        temp.append(arr['weights'])\n",
    "    return_arr = [idx, RANGE_REG_PENALTY[idx-1]]+[np.mean(temp, axis=0)]\n",
    "    return return_arr\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = get_mean_endpoint(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('{}_avg_endpoint_l2'.format(EXPERIMENT), pt[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
